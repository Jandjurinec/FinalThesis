{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import helper_functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from CNN import get_CNN_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numba import cuda \n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "  print(\"GPU is available\")\n",
    "else:\n",
    "  print(\"GPU is not available\")\n",
    "\n",
    "device = cuda.get_current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "def get_VGG():\n",
    "    base_model = VGG16(include_top=False, input_shape=(240,240,3))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.layers[0].trainable = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n",
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n",
      "Data is loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3509, 240, 240, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = helper_functions.load_data(full_size=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736464466.179801   27415 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5874 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-01-10 00:14:27.134723: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1745971200 exceeds 10% of free system memory.\n",
      "2025-01-10 00:14:28.711145: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1745971200 exceeds 10% of free system memory.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1736464470.438714   27515 service.cc:148] XLA service 0x7e29f8108940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1736464470.438741   27515 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2025-01-10 00:14:30.477151: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1736464470.570767   27515 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-01-10 00:14:34.900872: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,64,111,111]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,117,117]{3,2,1,0}, f32[64,128,7,7]{3,2,1,0}, f32[64]{0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-01-10 00:14:35.284143: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.384314498s\n",
      "Trying algorithm eng0{} for conv (f32[32,64,111,111]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,117,117]{3,2,1,0}, f32[64,128,7,7]{3,2,1,0}, f32[64]{0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-01-10 00:14:40.456187: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,128,117,117]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,111,111]{3,2,1,0}, f32[64,128,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-01-10 00:14:41.521265: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.065173676s\n",
      "Trying algorithm eng0{} for conv (f32[32,128,117,117]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,111,111]{3,2,1,0}, f32[64,128,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "I0000 00:00:1736464490.273286   27515 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-01-10 00:15:05.612047: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[30,64,111,111]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,128,117,117]{3,2,1,0}, f32[64,128,7,7]{3,2,1,0}, f32[64]{0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-01-10 00:15:05.795466: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.183511434s\n",
      "Trying algorithm eng0{} for conv (f32[30,64,111,111]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,128,117,117]{3,2,1,0}, f32[64,128,7,7]{3,2,1,0}, f32[64]{0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-01-10 00:15:11.131182: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[30,128,117,117]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,64,111,111]{3,2,1,0}, f32[64,128,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-01-10 00:15:12.066631: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.935555775s\n",
      "Trying algorithm eng0{} for conv (f32[30,128,117,117]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,64,111,111]{3,2,1,0}, f32[64,128,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-01-10 00:15:25.174015: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,64,111,111]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,117,117]{3,2,1,0}, f32[64,128,7,7]{3,2,1,0}, f32[64]{0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-01-10 00:15:25.438737: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.264896248s\n",
      "Trying algorithm eng0{} for conv (f32[32,64,111,111]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,117,117]{3,2,1,0}, f32[64,128,7,7]{3,2,1,0}, f32[64]{0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-01-10 00:19:17.704944: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[30,64,111,111]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,128,117,117]{3,2,1,0}, f32[64,128,7,7]{3,2,1,0}, f32[64]{0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-01-10 00:19:17.882114: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.177167633s\n",
      "Trying algorithm eng0{} for conv (f32[30,64,111,111]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,128,117,117]{3,2,1,0}, f32[64,128,7,7]{3,2,1,0}, f32[64]{0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9544159544159544 0.9728353140916808\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.0946, momentum=0.5815)\n",
    "model = get_CNN_model(optimizer, l2_reg = 0)\n",
    "\n",
    "acc, f1 = helper_functions.train(model, X_train, y_train, X_test, y_test, epochs=20, verbose=False)\n",
    "print(acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9601139601139601 0.9762308998302207\n"
     ]
    }
   ],
   "source": [
    "model = get_VGG()\n",
    "model.compile(loss='binary_crossentropy',optimizer='SGD',metrics=['accuracy'])\n",
    "acc, f1 = helper_functions.train(model, X_train, y_train, X_test, y_test, epochs=18,\n",
    "      verbose=False,\n",
    "      validation_split=0.25)\n",
    "print(acc, f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
